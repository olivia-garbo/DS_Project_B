import re
import spacy
from spacy.tokens import Span
from spacy.matcher import Matcher

nlp = spacy.load("en_core_web_lg")


# ======================================================
# 0. è§„åˆ™ï¼šå¼ºåˆ¶åˆå¹¶ â€œMr. Bennetâ€ â†’ PERSON å®ä½“
# ======================================================
def merge_titles(doc):

    matcher = Matcher(nlp.vocab)

    TITLE = ["Mr", "Mr.", "Mrs", "Mrs.", "Miss", "Ms", "Lady", "Sir",
             "Colonel", "Capt", "Captain", "Lord", "Rev", "General"]

    pattern = [
        {"TEXT": {"IN": TITLE}},
        {"IS_ALPHA": True, "OP": "+"}
    ]

    matcher.add("TITLE_NAME", [pattern])
    matches = matcher(doc)

    new_spans = []

    for _, start, end in matches:
        # åˆ›å»ºæ–°çš„ PERSON span
        span = Span(doc, start, end, label="PERSON")
        new_spans.append(span)

    # *** å…³é”®ï¼šåˆå¹¶æˆä¸€ä¸ªåˆ—è¡¨åå»é‡å  ***
    all_spans = list(doc.ents) + new_spans
    all_spans = spacy.util.filter_spans(all_spans)   # <- â­ å¿…é¡»åœ¨è¿™é‡Œè¿‡æ»¤

    doc.ents = all_spans
    return doc


# ======================================================
# å·¥å…·ï¼šç”Ÿæˆ Bennetâ€™s / Collinsâ€™
# ======================================================
def make_possessive(name):
    return name + "â€™" if name.endswith("s") else name + "â€™s"


# ======================================================
# å¼ºæ›¿æ¢æ ¸å¿ƒé€»è¾‘ï¼šæ›¿æ¢ he/him/his/she/her
# ======================================================
def patch_coref(sent, last_entity):

    if not last_entity:
        return sent

    name = last_entity.strip()

    # possessive
    poss = make_possessive(name)

    # æ›¿æ¢ä¼˜å…ˆçº§ï¼šé•¿çš„å…ˆæ›¿æ¢
    sent = re.sub(r"\bhis\b", poss, sent, flags=re.I)
    sent = re.sub(r"\bher\b", poss, sent, flags=re.I)

    sent = re.sub(r"\bhe\b", name, sent, flags=re.I)
    sent = re.sub(r"\bhim\b", name, sent, flags=re.I)
    sent = re.sub(r"\bshe\b", name, sent, flags=re.I)

    return sent


# ======================================================
# å¼ºæ›¿æ¢ä¸»é€»è¾‘
# ======================================================
def strong_coref(sentences):

    memory = []
    output = []

    for sent in sentences:

        doc = merge_titles(nlp(sent))   # â­ å…³é”®ï¼šå¼ºåˆ¶åˆå¹¶ Mr. Bennet

        # æŠ“ PERSON å®ä½“ï¼ˆtitle + surnameï¼‰
        persons = [ent.text for ent in doc.ents if ent.label_ == "PERSON"]

        # æ›´æ–° memory
        for p in persons:
            if p not in memory:
                memory.append(p)

        memory = memory[-5:]   # ä¿ç•™æœ€è¿‘ 5

        last_entity = memory[-1] if memory else None

        # å¼ºæ›¿æ¢ pronoun
        new_sent = patch_coref(sent, last_entity)
        output.append(new_sent)

    return "\n".join(output)


# ======================================================
# ä¸»ç¨‹åº
# ======================================================
def run_coref():

    print("ğŸ“˜ Loading textâ€¦")
    with open("clean_book.txt", "r", encoding="utf-8") as f:
        text = f.read()

    print("ğŸ“˜ Splitting sentencesâ€¦")
    sentences = [s.text for s in nlp(text).sents]

    print("âœ¨ Running PERSON-merged strong coreferenceâ€¦")
    resolved = strong_coref(sentences)

    print("ğŸ’¾ Saving resolved_book.txtâ€¦")
    with open("resolved_book.txt", "w", encoding="utf-8") as f:
        f.write(resolved)

    print("âœ… DONE â€” resolved_book.txt updated!")


if __name__ == "__main__":
    run_coref()
